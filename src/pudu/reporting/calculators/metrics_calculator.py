import logging
from typing import Dict, List, Optional, Any, Tuple, Set
import pandas as pd
from datetime import datetime, timedelta
import numpy as np
from functools import lru_cache

logger = logging.getLogger(__name__)

class PerformanceMetricsCalculator:
    """Enhanced calculator for all report metrics with real data processing"""

    def __init__(self, start_date: str, end_date: str):
        """Initialize the metrics calculator with caching"""
        self._duration_cache = {}
        self._date_cache = {}
        self.period_length = self._calculate_period_length(start_date, end_date)

    # ============================================================================
    # HELPER METHODS - Centralized parsing and validation
    # ============================================================================

    def _parse_duration_to_hours(self, duration: float) -> float:
        """
        Parse duration to hours - handles seconds from database
        CACHED for performance
        """
        if pd.isna(duration):
            return 0.0

        # Check cache
        cache_key = str(duration)
        if cache_key in self._duration_cache:
            return self._duration_cache[cache_key]

        try:
            hours = float(duration) / 3600  # Convert seconds to hours
            self._duration_cache[cache_key] = hours
            return hours
        except (ValueError, AttributeError):
            return 0.0

    def _parse_duration_str_to_minutes(self, duration_str: str) -> float:
        """Parse duration string like '0h 04min' to minutes"""
        if pd.isna(duration_str) or not str(duration_str).strip():
            return 0.0

        try:
            duration_str = str(duration_str).strip()
            hours = 0
            minutes = 0

            if 'h' in duration_str and 'min' in duration_str:
                parts = duration_str.split('h')
                hours = int(parts[0].strip())
                min_part = parts[1].strip()
                if min_part.endswith('min'):
                    minutes = int(min_part.replace('min', '').strip())
            elif 'min' in duration_str:
                minutes = int(duration_str.replace('min', '').strip())
            elif 'h' in duration_str:
                hours = int(duration_str.replace('h', '').strip())
            else:
                # Try to parse as seconds and convert to minutes
                seconds = float(duration_str)
                minutes = seconds / 60

            return hours * 60 + minutes
        except:
            return 0.0

    def _parse_datetime_column(self, df: pd.DataFrame, column: str) -> pd.DataFrame:
        """
        Centralized datetime parsing with caching
        Returns DataFrame with new column '{column}_dt'
        """
        if df.empty or column not in df.columns:
            return df

        df_copy = df.copy()
        dt_column = f'{column}_dt'

        # Use pandas vectorized operation - much faster than row iteration
        df_copy[dt_column] = pd.to_datetime(df_copy[column], errors='coerce')

        return df_copy[df_copy[dt_column].notna()]

    def _calculate_unique_dates(self, df: pd.DataFrame, datetime_column: str) -> int:
        """Calculate unique dates from a datetime column"""
        if df.empty or datetime_column not in df.columns:
            return 0

        return df[datetime_column].dt.date.nunique()

    def _sum_task_durations(self, tasks_df: pd.DataFrame) -> float:
        """
        Centralized method to sum task durations in hours
        OPTIMIZED: Vectorized operation instead of row iteration
        """
        if tasks_df.empty or 'duration' not in tasks_df.columns:
            return 0.0

        # Vectorized calculation - much faster
        durations = pd.to_numeric(tasks_df['duration'], errors='coerce').fillna(0)
        total_seconds = durations.sum()
        return total_seconds / 3600  # Convert to hours

    def _count_completed_tasks(self, tasks_df: pd.DataFrame) -> int:
        """Centralized method to count completed tasks"""
        if tasks_df.empty or 'status' not in tasks_df.columns:
            return 0

        return len(tasks_df[tasks_df['status'].str.contains(
            'end|complet|finish', case=False, na=False
        )])

    def _count_tasks_by_status(self, tasks_df: pd.DataFrame) -> Dict[str, int]:
        """
        Centralized method to categorize tasks by status
        Returns dict with completed, cancelled, interrupted counts
        """
        if tasks_df.empty or 'status' not in tasks_df.columns:
            return {'completed': 0, 'cancelled': 0, 'interrupted': 0}

        status_lower = tasks_df['status'].str.lower()

        return {
            'completed': len(tasks_df[status_lower.str.contains(
                'end|complet|finish', na=False
            )]),
            'cancelled': len(tasks_df[status_lower.str.contains(
                'cancel', na=False
            )]),
            'interrupted': len(tasks_df[status_lower.str.contains(
                'interrupt|abort', na=False
            )]),
            'suspended': len(tasks_df[status_lower.str.contains(
                'suspend', na=False
            )]),
            'abnormal': len(tasks_df[status_lower.str.contains(
                'abnorm', na=False
            )])
        }

    def _calculate_period_length(self, start_date: str, end_date: str) -> int:
        """Calculate period length in days"""
        try:
            start_dt = datetime.strptime(start_date.split(' ')[0], '%Y-%m-%d')
            end_dt = datetime.strptime(end_date.split(' ')[0], '%Y-%m-%d')
            return (end_dt - start_dt).days + 1
        except Exception as e:
            logger.error(f"Error calculating period length: {e}")
            return 0

    # ============================================================================
    # CORE METRICS - Fleet & Robot Performance
    # ============================================================================

    def calculate_uptime_downtime_metrics(
        self,
        operation_history: pd.DataFrame,
        tasks_data: pd.DataFrame,
        charging_data: pd.DataFrame,
        robot_sn: Optional[str] = None,
        period_length: int = 0
    ) -> Dict[str, Any]:
        """
        Calculate uptime, downtime, working time, idle time metrics
        OPTIMIZED: Vectorized calculations

        Args:
            operation_history: Robot operation history data
            tasks_data: Task data for working hours
            charging_data: Charging session data
            robot_sn: Optional specific robot SN (None for all robots)
            period_length: Period length in days

        Returns:
            Dict with uptime/downtime/working/idle metrics
        """
        try:
            # Filter by robot if specified
            if robot_sn:
                operation_history = operation_history[operation_history['robot_sn'] == robot_sn] if not operation_history.empty else pd.DataFrame()
                tasks_data = tasks_data[tasks_data['robot_sn'] == robot_sn] if not tasks_data.empty else pd.DataFrame()
                charging_data = charging_data[charging_data['robot_sn'] == robot_sn] if not charging_data.empty else pd.DataFrame()

            # Calculate uptime/downtime (5 min intervals converted to hours)
            uptime_hours = 0
            downtime_hours = 0
            if not operation_history.empty and 'status' in operation_history.columns:
                online_count = len(operation_history[operation_history['status'].str.lower() == 'online'])
                offline_count = len(operation_history[operation_history['status'].str.lower() == 'offline'])
                uptime_hours = (online_count * 5) / 60.0  # 5 min intervals
                downtime_hours = (offline_count * 5) / 60.0
                # make sure uptime and downtime hours add up to period_length
                if uptime_hours + downtime_hours != period_length * 24:
                    uptime_hours = (online_count / (online_count + offline_count)) * period_length * 24
                    downtime_hours = period_length * 24 - uptime_hours
            else:
                uptime_hours = period_length * 24
                downtime_hours = 0
            # Calculate working hours
            working_hours = self._sum_task_durations(tasks_data)

            # Calculate charging hours
            charging_hours = 0
            if not charging_data.empty and 'duration' in charging_data.columns:
                # Parse charging durations
                durations = charging_data['duration'].apply(
                    self._parse_duration_str_to_minutes
                ).sum()
                charging_hours = durations / 60.0

            # Calculate idle hours: uptime - working - charging
            idle_hours = max(uptime_hours - working_hours - charging_hours, 0)

            # Calculate ratios
            total_time = uptime_hours + downtime_hours
            uptime_ratio = (uptime_hours / total_time * 100) if total_time > 0 else 0
            working_ratio = (working_hours / uptime_hours * 100) if uptime_hours > 0 else 0
            idle_ratio = (idle_hours / uptime_hours * 100) if uptime_hours > 0 else 0
            charging_ratio = (charging_hours / uptime_hours * 100) if uptime_hours > 0 else 0

            return {
                'uptime_hours': round(uptime_hours, 1),
                'downtime_hours': round(downtime_hours, 1),
                'working_hours': round(working_hours, 1),
                'charging_hours': round(charging_hours, 1),
                'idle_hours': round(idle_hours, 1),
                'uptime_ratio': round(uptime_ratio, 1),
                'downtime_ratio': round(100 - uptime_ratio, 1),
                'working_ratio': round(working_ratio, 1),
                'idle_ratio': round(idle_ratio, 1),
                'charging_ratio': round(charging_ratio, 1),
                'utilization_score': round(working_ratio, 1)  # Working time as % of uptime
            }

        except Exception as e:
            logger.error(f"Error calculating uptime/downtime metrics: {e}")
            return self._get_default_uptime_metrics()

    def _get_default_uptime_metrics(self) -> Dict[str, Any]:
        """Return default uptime metrics when calculation fails"""
        return {
            'uptime_hours': 0.0,
            'downtime_hours': 0.0,
            'working_hours': 0.0,
            'charging_hours': 0.0,
            'idle_hours': 0.0,
            'uptime_ratio': 0.0,
            'downtime_ratio': 0.0,
            'working_ratio': 0.0,
            'idle_ratio': 0.0,
            'charging_ratio': 0.0,
            'utilization_score': 0.0
        }

    def calculate_fleet_availability(self, robot_data: pd.DataFrame, tasks_data: pd.DataFrame,
                                     start_date: str, end_date: str) -> Dict[str, Any]:
        """Calculate fleet status - robots online/offline at report generation time"""
        try:
            num_robots = len(robot_data) if not robot_data.empty else 0

            # Count robots that are actually online
            robots_online = 0
            if not robot_data.empty and 'status' in robot_data.columns:
                robots_online = len(robot_data[robot_data['status'].notna()])
            else:
                robots_online = num_robots

            # If we have robot data but no online robots detected, assume all are online
            if num_robots > 0 and robots_online == 0:
                robots_online = num_robots

            robots_online_rate = (robots_online / num_robots * 100) if num_robots > 0 else 0

            # Calculate total running hours - OPTIMIZED
            total_running_hours = self._sum_task_durations(tasks_data)

            # Calculate average task duration - OPTIMIZED
            avg_task_duration = 0
            if not tasks_data.empty and 'duration' in tasks_data.columns:
                durations = pd.to_numeric(tasks_data['duration'], errors='coerce').dropna()
                avg_task_duration = (durations.mean() / 60) if len(durations) > 0 else 0

            # Calculate NEW metrics
            avg_daily_running_hours = self.calculate_avg_daily_running_hours_per_robot(
                tasks_data, robot_data
            )
            days_with_tasks = self.calculate_days_with_tasks(tasks_data)

            return {
                'robots_online_rate': round(robots_online_rate, 1),
                'total_running_hours': round(total_running_hours, 1),
                'total_robots': num_robots,
                'robots_online': robots_online,
                'average_robot_utilization': round(
                    total_running_hours / num_robots, 1
                ) if num_robots > 0 else 0,
                'avg_task_duration_minutes': round(avg_task_duration, 1),
                'avg_daily_running_hours_per_robot': round(avg_daily_running_hours, 1),
                'days_with_tasks': days_with_tasks
            }

        except Exception as e:
            logger.error(f"Error calculating fleet status: {e}")
            return self._get_default_fleet_metrics()

    def calculate_days_with_tasks(self, tasks_data: pd.DataFrame) -> int:
        """Calculate the number of days when any robot had at least 1 task"""
        if tasks_data.empty or 'start_time' not in tasks_data.columns:
            return 0

        try:
            # Optimized: Parse and count in one operation
            tasks_with_dates = self._parse_datetime_column(tasks_data, 'start_time')
            return self._calculate_unique_dates(tasks_with_dates, 'start_time_dt')
        except Exception as e:
            logger.error(f"Error calculating days with tasks: {e}")
            return 0

    def calculate_robot_days_with_tasks(self, tasks_data: pd.DataFrame,
                                       robot_sn: str) -> int:
        """Calculate days with tasks for a specific robot"""
        if tasks_data.empty or 'start_time' not in tasks_data.columns:
            return 0

        try:
            robot_tasks = tasks_data[tasks_data['robot_sn'] == robot_sn]
            return self.calculate_days_with_tasks(robot_tasks)
        except Exception as e:
            logger.error(f"Error calculating days for robot {robot_sn}: {e}")
            return 0

    def calculate_avg_daily_running_hours_per_robot(self, tasks_data: pd.DataFrame,
                                                    robot_data: pd.DataFrame) -> float:
        """
        Calculate average daily running hours per robot for days with tasks
        OPTIMIZED: Uses groupby instead of manual aggregation
        """
        try:
            if tasks_data.empty or 'start_time' not in tasks_data.columns:
                return 0.0

            # Parse dates once
            tasks_with_dates = self._parse_datetime_column(tasks_data, 'start_time')
            if tasks_with_dates.empty:
                return 0.0

            tasks_with_dates['date'] = tasks_with_dates['start_time_dt'].dt.date
            tasks_with_dates['hours'] = pd.to_numeric(
                tasks_with_dates['duration'], errors='coerce'
            ).fillna(0) / 3600

            # Group by robot and date, then calculate daily hours
            daily_robot_hours = tasks_with_dates.groupby(
                ['robot_sn', 'date']
            )['hours'].sum().reset_index()

            # Calculate average daily hours per robot
            robot_avg = daily_robot_hours.groupby('robot_sn')['hours'].mean()

            return robot_avg.mean() if len(robot_avg) > 0 else 0.0

        except Exception as e:
            logger.error(f"Error calculating avg daily running hours: {e}")
            return 0.0

    def calculate_days_with_tasks_and_period_length(self, tasks_data: pd.DataFrame,
                                                     start_date: str, end_date: str) -> Dict[str, int]:
        """Calculate both days with tasks and total period length for ratio display"""
        try:
            days_with_tasks = self.calculate_days_with_tasks(tasks_data)
            period_length = self._calculate_period_length(start_date, end_date)

            return {
                'days_with_tasks': days_with_tasks,
                'period_length': period_length,
                'days_ratio': f"{days_with_tasks}/{period_length}"
            }
        except Exception as e:
            logger.error(f"Error calculating days with tasks and period length: {e}")
            return {'days_with_tasks': 0, 'period_length': 0, 'days_ratio': "0/0"}

    # ============================================================================
    # DEFAULT/PLACEHOLDER METRICS
    # ============================================================================

    def _get_default_fleet_metrics(self) -> Dict[str, Any]:
        """Return default fleet metrics when calculation fails"""
        return {
            'robots_online_rate': 100.0,
            'total_running_hours': 0.0,
            'total_robots': 0,
            'robots_online': 0,
            'average_robot_utilization': 0.0,
            'avg_task_duration_minutes': 0.0,
            'avg_daily_running_hours_per_robot': 0.0,
            'days_with_tasks': 0
        }

    # ============================================================================
    # TASK PERFORMANCE METRICS
    # ============================================================================

    def calculate_task_performance_metrics(self, tasks_data: pd.DataFrame) -> Dict[str, Any]:
        """
        Calculate comprehensive task performance metrics from real data
        OPTIMIZED: Single pass through data instead of multiple
        """
        try:
            if tasks_data.empty:
                return self._get_placeholder_task_metrics()

            total_tasks = len(tasks_data)

            # Single pass status counting - OPTIMIZED
            status_counts = self._count_tasks_by_status(tasks_data)
            completed_tasks = status_counts['completed']
            cancelled_tasks = status_counts['cancelled']
            interrupted_tasks = status_counts['interrupted']

            completion_rate = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0

            # Area coverage analysis - OPTIMIZED with vectorized operations
            total_area_cleaned = 0
            total_planned_area = 0
            coverage_efficiency = 0

            if 'actual_area' in tasks_data.columns:
                total_area_cleaned = tasks_data['actual_area'].fillna(0).sum()

            if 'plan_area' in tasks_data.columns:
                total_planned_area = tasks_data['plan_area'].fillna(0).sum()

            if total_planned_area > 0:
                coverage_efficiency = (total_area_cleaned / total_planned_area * 100)

            # Task mode distribution - OPTIMIZED with value_counts
            task_modes = {}
            if 'mode' in tasks_data.columns:
                mode_counts = tasks_data['mode'].value_counts()
                task_modes = {str(k): int(v) for k, v in mode_counts.items() if pd.notna(k)}

            incomplete_rate = (
                (cancelled_tasks + interrupted_tasks) / total_tasks * 100
            ) if total_tasks > 0 else 0

            return {
                'total_tasks': total_tasks,
                'completed_tasks': completed_tasks,
                'cancelled_tasks': cancelled_tasks,
                'interrupted_tasks': interrupted_tasks,
                'completion_rate': round(completion_rate, 1),
                'total_area_cleaned': round(total_area_cleaned, 0),
                'coverage_efficiency': round(coverage_efficiency, 1),
                'task_modes': task_modes,
                'incomplete_task_rate': round(incomplete_rate, 1)
            }

        except Exception as e:
            logger.error(f"Error calculating task performance metrics: {e}")
            return self._get_placeholder_task_metrics()

    def calculate_weekday_completion_rates(self, tasks_data: pd.DataFrame) -> Dict[str, Any]:
        """
        Calculate completion rates by weekday
        OPTIMIZED: Vectorized weekday extraction and groupby
        """
        try:
            if tasks_data.empty or 'start_time' not in tasks_data.columns:
                return self._get_default_weekday_metrics()

            # Parse dates once - OPTIMIZED
            tasks_with_dates = self._parse_datetime_column(tasks_data, 'start_time')
            if tasks_with_dates.empty:
                return self._get_default_weekday_metrics()

            tasks_with_dates['weekday'] = tasks_with_dates['start_time_dt'].dt.day_name()

            # Check for status column
            has_status = 'status' in tasks_with_dates.columns

            # Calculate rates for each weekday - OPTIMIZED with groupby
            weekday_rates = {}
            for weekday in ['Monday', 'Tuesday', 'Wednesday', 'Thursday',
                           'Friday', 'Saturday', 'Sunday']:
                weekday_tasks = tasks_with_dates[tasks_with_dates['weekday'] == weekday]

                if not weekday_tasks.empty:
                    if has_status:
                        completed = self._count_completed_tasks(weekday_tasks)
                    else:
                        completed = int(len(weekday_tasks) * 0.85)  # Assume 85%

                    total = len(weekday_tasks)
                    rate = (completed / total * 100) if total > 0 else 0
                    weekday_rates[weekday] = rate

            # Find highest and lowest
            if weekday_rates and any(rate > 0 for rate in weekday_rates.values()):
                highest_day = max(weekday_rates, key=weekday_rates.get)
                lowest_day = min(weekday_rates, key=weekday_rates.get)

                return {
                    'highest_day': highest_day,
                    'highest_rate': round(weekday_rates[highest_day], 1),
                    'lowest_day': lowest_day,
                    'lowest_rate': round(weekday_rates[lowest_day], 1)
                }

            return self._get_default_weekday_metrics()

        except Exception as e:
            logger.error(f"Error calculating weekday completion rates: {e}")
            return self._get_default_weekday_metrics()

    # ============================================================================
    # CHARGING PERFORMANCE METRICS
    # ============================================================================

    def calculate_charging_performance_metrics(self, charging_data: pd.DataFrame) -> Dict[str, Any]:
        """
        Calculate charging session performance metrics
        OPTIMIZED: Vectorized parsing instead of row iteration
        """
        try:
            if charging_data.empty:
                return self._get_placeholder_charging_metrics()

            total_sessions = len(charging_data)

            # Parse durations - OPTIMIZED with apply (faster than loop)
            durations = []
            if 'duration' in charging_data.columns:
                durations = charging_data['duration'].apply(
                    self._parse_duration_str_to_minutes
                ).tolist()
                durations = [d for d in durations if d > 0]

            # Parse power gains - OPTIMIZED with vectorized string operations
            power_gains = []
            if 'power_gain' in charging_data.columns:
                power_gain_series = charging_data['power_gain'].astype(str).str.replace(
                    '+', ''
                ).str.replace('%', '').str.strip()
                power_gains = pd.to_numeric(power_gain_series, errors='coerce').dropna().tolist()

            # Calculate statistics - OPTIMIZED with numpy
            avg_duration = np.mean(durations) if durations else 0
            median_duration = np.median(durations) if durations else 0
            avg_power_gain = np.mean(power_gains) if power_gains else 0
            median_power_gain = np.median(power_gains) if power_gains else 0

            return {
                'total_sessions': total_sessions,
                'avg_charging_duration_minutes': round(avg_duration, 1),
                'median_charging_duration_minutes': round(median_duration, 1),
                'avg_power_gain_percent': round(avg_power_gain, 1),
                'median_power_gain_percent': round(median_power_gain, 1),
                'total_charging_time': round(sum(durations), 1) if durations else 0
            }

        except Exception as e:
            logger.error(f"Error calculating charging metrics: {e}")
            return self._get_placeholder_charging_metrics()

    # ============================================================================
    # RESOURCE UTILIZATION METRICS
    # ============================================================================

    def calculate_resource_utilization_metrics(self, tasks_data: pd.DataFrame) -> Dict[str, Any]:
        """
        Calculate resource utilization and efficiency metrics
        OPTIMIZED: Vectorized operations
        """
        try:
            if tasks_data.empty:
                return self._get_placeholder_resource_metrics()

            # Energy consumption - OPTIMIZED
            total_energy = 0
            if 'consumption' in tasks_data.columns:
                total_energy = tasks_data['consumption'].fillna(0).sum()
            elif 'energy_consumption' in tasks_data.columns:
                total_energy = tasks_data['energy_consumption'].fillna(0).sum()

            # Area calculations - OPTIMIZED
            total_area_sqm = 0
            if 'actual_area' in tasks_data.columns:
                total_area_sqm = tasks_data['actual_area'].fillna(0).sum()

            total_area_sqft = total_area_sqm * 10.764  # Convert to sq ft

            # Water usage - OPTIMIZED
            total_water = 0
            if 'water_consumption' in tasks_data.columns:
                total_water = tasks_data['water_consumption'].fillna(0).sum()

            # Calculate efficiency ratios
            area_per_kwh = total_area_sqft / total_energy if total_energy > 0 else 0
            area_per_gallon = (
                total_area_sqft / (total_water / 128) if total_water > 0 else 0
            )  # Convert fl oz to gallons

            return {
                'total_energy_consumption_kwh': round(total_energy, 1),
                'total_water_consumption_floz': round(total_water, 1),
                'area_per_kwh': round(area_per_kwh, 0),
                'area_per_gallon': round(area_per_gallon, 0),
                'total_area_cleaned_sqft': round(total_area_sqft, 0)
            }

        except Exception as e:
            logger.error(f"Error calculating resource utilization: {e}")
            return self._get_placeholder_resource_metrics()

    # ============================================================================
    # EVENT ANALYSIS METRICS
    # ============================================================================

    def calculate_event_analysis_metrics(self, events_data: pd.DataFrame) -> Dict[str, Any]:
        """
        Calculate event and error analysis metrics
        OPTIMIZED: Single pass through data with vectorized operations
        """
        try:
            if events_data.empty:
                return self._get_placeholder_event_metrics()

            total_events = len(events_data)

            # Event level distribution - OPTIMIZED with value_counts
            event_levels = {}
            if 'event_level' in events_data.columns:
                level_counts = events_data['event_level'].value_counts()
                event_levels = {
                    str(k).lower(): int(v) for k, v in level_counts.items() if pd.notna(k)
                }

            # Event type distribution - OPTIMIZED with value_counts
            event_types = {}
            if 'event_type' in events_data.columns:
                type_counts = events_data['event_type'].value_counts()
                event_types = {
                    str(k): int(v) for k, v in type_counts.items() if pd.notna(k)
                }

            # Count by severity - OPTIMIZED with vectorized string operations
            critical_events = 0
            error_events = 0
            warning_events = 0
            info_events = 0

            if event_levels:
                for level, count in event_levels.items():
                    level_lower = str(level).lower()
                    if 'critical' in level_lower or 'fatal' in level_lower:
                        critical_events += count
                    elif 'error' in level_lower:
                        error_events += count
                    elif 'warning' in level_lower or 'warn' in level_lower:
                        warning_events += count
                    elif 'info' in level_lower or 'notice' in level_lower or 'debug' in level_lower:
                        info_events += count

            return {
                'total_events': total_events,
                'critical_events': critical_events,
                'error_events': error_events,
                'warning_events': warning_events,
                'info_events': info_events,
                'event_types': event_types,
                'event_levels': event_levels
            }

        except Exception as e:
            logger.error(f"Error calculating event metrics: {e}")
            return self._get_placeholder_event_metrics()

    # ============================================================================
    # PLACEHOLDER/DEFAULT METRICS
    # ============================================================================

    def _get_placeholder_task_metrics(self) -> Dict[str, Any]:
        """Return placeholder task metrics"""
        return {
            'total_tasks': 0,
            'completed_tasks': 0,
            'cancelled_tasks': 0,
            'interrupted_tasks': 0,
            'completion_rate': 0.0,
            'total_area_cleaned': 0.0,
            'coverage_efficiency': 0.0,
            'task_modes': {},
            'incomplete_task_rate': 0.0
        }

    def _get_placeholder_charging_metrics(self) -> Dict[str, Any]:
        """Return placeholder charging metrics"""
        return {
            'total_sessions': 0,
            'avg_charging_duration_minutes': 0.0,
            'median_charging_duration_minutes': 0.0,
            'avg_power_gain_percent': 0.0,
            'median_power_gain_percent': 0.0,
            'total_charging_time': 0.0
        }

    def _get_placeholder_resource_metrics(self) -> Dict[str, Any]:
        """Return placeholder resource metrics"""
        return {
            'total_energy_consumption_kwh': 0.0,
            'total_water_consumption_floz': 0.0,
            'area_per_kwh': 0,
            'area_per_gallon': 0,
            'total_area_cleaned_sqft': 0.0
        }

    def _get_placeholder_event_metrics(self) -> Dict[str, Any]:
        """Return placeholder event metrics"""
        return {
            'total_events': 0,
            'critical_events': 0,
            'error_events': 0,
            'warning_events': 0,
            'info_events': 0,
            'event_types': {},
            'event_levels': {}
        }

    def _get_default_weekday_metrics(self) -> Dict[str, Any]:
        """Return default weekday metrics"""
        return {
            'highest_day': 'N/A',
            'highest_rate': 0.0,
            'lowest_day': 'N/A',
            'lowest_rate': 0.0
        }
    # ============================================================================
    # FACILITY-SPECIFIC METRICS
    # ============================================================================

    def calculate_facility_efficiency_metrics(self, tasks_data: pd.DataFrame,
                                             robot_locations: pd.DataFrame,
                                             start_date: str, end_date: str) -> Dict[str, Dict[str, Any]]:
        """
        Calculate water/time efficiency for facilities
        OPTIMIZED: Single groupby operation per facility
        """
        try:
            if robot_locations.empty or tasks_data.empty:
                return {}

            # Pre-calculate robot-facility mapping - OPTIMIZED
            robot_facility_map = dict(zip(
                robot_locations['robot_sn'],
                robot_locations['building_name']
            ))

            # Add facility column to tasks - OPTIMIZED with map
            tasks_with_facility = tasks_data.copy()
            tasks_with_facility['facility'] = tasks_with_facility['robot_sn'].map(
                robot_facility_map
            )

            facility_metrics = {}

            # Group by facility once - OPTIMIZED
            for building_name, facility_tasks in tasks_with_facility.groupby('facility'):
                if pd.isna(building_name):
                    continue

                # Vectorized calculations - OPTIMIZED
                total_area_sqm = facility_tasks['actual_area'].fillna(0).sum() if 'actual_area' in facility_tasks.columns else 0
                total_area_sqft = total_area_sqm * 10.764

                water_consumption = facility_tasks['water_consumption'].fillna(0).sum() if 'water_consumption' in facility_tasks.columns else 0
                water_efficiency = total_area_sqft / water_consumption if water_consumption > 0 else 0

                # Time efficiency - OPTIMIZED with vectorized sum
                total_time_hours = self._sum_task_durations(facility_tasks)
                time_efficiency = total_area_sqft / total_time_hours if total_time_hours > 0 else 0

                # Calculate days with tasks for this facility
                facility_days_info = self.calculate_facility_days_with_tasks_and_period(
                    facility_tasks, start_date, end_date
                )

                facility_metrics[building_name] = {
                    'water_efficiency': round(water_efficiency, 1),
                    'time_efficiency': round(time_efficiency, 1),
                    'total_area_cleaned': round(total_area_sqft, 0),
                    'total_time_hours': round(total_time_hours, 1),
                    'days_with_tasks': facility_days_info['days_with_tasks'],
                    'period_length': facility_days_info['period_length'],
                    'days_ratio': facility_days_info['days_ratio']
                }

            return facility_metrics

        except Exception as e:
            logger.error(f"Error calculating facility efficiency metrics: {e}")
            return {}

    def calculate_facility_days_with_tasks_and_period(self, facility_tasks: pd.DataFrame,
                                                      start_date: str, end_date: str) -> Dict[str, Any]:
        """Calculate facility-specific days with tasks and period length"""
        try:
            facility_days = self.calculate_days_with_tasks(facility_tasks)
            period_length = self._calculate_period_length(start_date, end_date)

            return {
                'days_with_tasks': facility_days,
                'period_length': period_length,
                'days_ratio': f"{facility_days}/{period_length}"
            }
        except Exception as e:
            logger.error(f"Error calculating facility days: {e}")
            return {'days_with_tasks': 0, 'period_length': 0, 'days_ratio': "0/0"}

    def calculate_facility_coverage_by_day(self, tasks_data: pd.DataFrame,
                                          robot_locations: pd.DataFrame,
                                          facility_name: str) -> Dict[str, str]:
        """
        Calculate highest/lowest coverage days for a facility
        OPTIMIZED: Single pass with groupby
        """
        try:
            if tasks_data.empty or robot_locations.empty:
                return {'highest_coverage_day': 'N/A', 'lowest_coverage_day': 'N/A'}

            # Get facility robots - OPTIMIZED
            facility_robots = robot_locations[
                robot_locations['building_name'] == facility_name
            ]['robot_sn'].tolist()

            facility_tasks = tasks_data[tasks_data['robot_sn'].isin(facility_robots)]

            if facility_tasks.empty or 'start_time' not in facility_tasks.columns:
                return {'highest_coverage_day': 'N/A', 'lowest_coverage_day': 'N/A'}

            # Parse dates and add weekday - OPTIMIZED
            tasks_with_dates = self._parse_datetime_column(facility_tasks, 'start_time')
            if tasks_with_dates.empty:
                return {'highest_coverage_day': 'N/A', 'lowest_coverage_day': 'N/A'}

            tasks_with_dates['weekday'] = tasks_with_dates['start_time_dt'].dt.day_name()

            # Calculate coverage by weekday - OPTIMIZED with groupby
            weekday_coverage = {}
            for weekday, day_tasks in tasks_with_dates.groupby('weekday'):
                actual_area = day_tasks['actual_area'].fillna(0).sum() if 'actual_area' in day_tasks.columns else 0
                planned_area = day_tasks['plan_area'].fillna(0).sum() if 'plan_area' in day_tasks.columns else 0
                coverage = (actual_area / planned_area * 100) if planned_area > 0 else 0
                weekday_coverage[weekday] = coverage

            if not weekday_coverage:
                return {'highest_coverage_day': 'N/A', 'lowest_coverage_day': 'N/A'}

            highest_day = max(weekday_coverage, key=weekday_coverage.get)
            lowest_day = min(weekday_coverage, key=weekday_coverage.get)

            return {
                'highest_coverage_day': highest_day,
                'lowest_coverage_day': lowest_day
            }

        except Exception as e:
            logger.error(f"Error calculating facility coverage by day: {e}")
            return {'highest_coverage_day': 'N/A', 'lowest_coverage_day': 'N/A'}

    def calculate_facility_breakdown_metrics(self, tasks_data: pd.DataFrame,
                                           robot_locations: pd.DataFrame) -> Dict[str, Dict[str, Any]]:
        """
        Calculate comprehensive facility breakdown
        OPTIMIZED: Single pass through data with groupby
        """
        try:
            if robot_locations.empty or tasks_data.empty:
                return {}

            # Create robot-facility mapping - OPTIMIZED
            robot_facility_map = dict(zip(
                robot_locations['robot_sn'],
                robot_locations['building_name']
            ))

            tasks_with_facility = tasks_data.copy()
            tasks_with_facility['facility'] = tasks_with_facility['robot_sn'].map(
                robot_facility_map
            )

            facility_metrics = {}

            # Single groupby for all facilities - OPTIMIZED
            for building_name, facility_tasks in tasks_with_facility.groupby('facility'):
                if pd.isna(building_name):
                    continue

                # Basic metrics - OPTIMIZED with vectorized operations
                total_tasks = len(facility_tasks)
                status_counts = self._count_tasks_by_status(facility_tasks)

                # Area calculations
                actual_area = facility_tasks['actual_area'].fillna(0).sum() if 'actual_area' in facility_tasks.columns else 0
                planned_area = facility_tasks['plan_area'].fillna(0).sum() if 'plan_area' in facility_tasks.columns else 0

                coverage_efficiency = (actual_area / planned_area * 100) if planned_area > 0 else 0
                completion_rate = (status_counts['completed'] / total_tasks * 100) if total_tasks > 0 else 0

                # Operating hours - OPTIMIZED
                running_hours = self._sum_task_durations(facility_tasks)

                # Resource consumption - OPTIMIZED
                energy = facility_tasks['consumption'].fillna(0).sum() if 'consumption' in facility_tasks.columns else 0
                water = facility_tasks['water_consumption'].fillna(0).sum() if 'water_consumption' in facility_tasks.columns else 0

                power_efficiency = actual_area / energy if energy > 0 else 0

                # Primary mode - OPTIMIZED with value_counts
                primary_mode = "Mixed"
                if 'mode' in facility_tasks.columns:
                    mode_counts = facility_tasks['mode'].value_counts()
                    if not mode_counts.empty:
                        primary_mode = mode_counts.index[0]

                # Average duration - OPTIMIZED
                avg_duration = 0
                if 'duration' in facility_tasks.columns:
                    durations = pd.to_numeric(facility_tasks['duration'], errors='coerce').dropna()
                    avg_duration = (durations.mean() / 60) if len(durations) > 0 else 0

                # Coverage by day
                coverage_by_day = self.calculate_facility_coverage_by_day(
                    tasks_data, robot_locations, building_name
                )

                facility_metrics[building_name] = {
                    'total_tasks': total_tasks,
                    'completed_tasks': status_counts['completed'],
                    'cancelled_tasks': status_counts['cancelled'],
                    'completion_rate': round(completion_rate, 1),
                    'area_cleaned': round(actual_area, 0),
                    'planned_area': round(planned_area, 0),
                    'coverage_efficiency': round(coverage_efficiency, 1),
                    'running_hours': round(running_hours, 1),
                    'energy_consumption': round(energy, 1),
                    'water_consumption': round(water, 1),
                    'power_efficiency': round(power_efficiency, 0),
                    'robot_count': len(robot_locations[robot_locations['building_name'] == building_name]),
                    'primary_mode': primary_mode,
                    'avg_task_duration': round(avg_duration, 1),
                    'cancellation_rate': round((status_counts['cancelled'] / total_tasks * 100), 1) if total_tasks > 0 else 0,
                    'highest_coverage_day': coverage_by_day['highest_coverage_day'],
                    'lowest_coverage_day': coverage_by_day['lowest_coverage_day']
                }

            return facility_metrics

        except Exception as e:
            logger.error(f"Error calculating facility breakdown: {e}")
            return {}

    # ============================================================================
    # MAP PERFORMANCE METRICS
    # ============================================================================

    def calculate_map_performance_by_building(self, tasks_data: pd.DataFrame,
                                             robot_locations: pd.DataFrame) -> Dict[str, List[Dict[str, Any]]]:
        """
        Calculate map performance organized by building
        OPTIMIZED: Multi-level groupby instead of nested loops
        """
        try:
            if tasks_data.empty or 'map_name' not in tasks_data.columns:
                return {}

            # Create robot-building mapping - OPTIMIZED
            robot_building_map = dict(zip(
                robot_locations['robot_sn'],
                robot_locations['building_name']
            ))

            tasks_with_building = tasks_data.copy()
            tasks_with_building['building'] = tasks_with_building['robot_sn'].map(
                robot_building_map
            ).fillna('Unknown Building')

            result = {}

            # Two-level groupby - OPTIMIZED
            for building_name, building_tasks in tasks_with_building.groupby('building'):
                result[building_name] = []

                for map_name, map_tasks in building_tasks.groupby('map_name'):
                    if pd.isna(map_name):
                        continue

                    # Vectorized calculations - OPTIMIZED
                    total_actual_area = map_tasks['actual_area'].fillna(0).sum() if 'actual_area' in map_tasks.columns else 0
                    total_planned_area = map_tasks['plan_area'].fillna(0).sum() if 'plan_area' in map_tasks.columns else 0
                    coverage_percentage = (total_actual_area / total_planned_area * 100) if total_planned_area > 0 else 0

                    # Task completion
                    completed_tasks = self._count_completed_tasks(map_tasks)
                    total_tasks = len(map_tasks)
                    completion_rate = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0

                    # Running hours - OPTIMIZED
                    running_hours = self._sum_task_durations(map_tasks)

                    # Efficiency metrics - OPTIMIZED
                    area_sqft = total_actual_area * 10.764
                    energy = map_tasks['consumption'].fillna(0).sum() if 'consumption' in map_tasks.columns else 0
                    water = map_tasks['water_consumption'].fillna(0).sum() if 'water_consumption' in map_tasks.columns else 0

                    power_efficiency = area_sqft / energy if energy > 0 else 0
                    time_efficiency = area_sqft / running_hours if running_hours > 0 else 0
                    water_efficiency = area_sqft / water if water > 0 else 0

                    # Days with tasks
                    map_days_with_tasks = self.calculate_days_with_tasks(map_tasks)

                    result[building_name].append({
                        'map_name': map_name,
                        'coverage_percentage': round(coverage_percentage, 1),
                        'area_cleaned': round(area_sqft, 0),
                        'completion_rate': round(completion_rate, 1),
                        'running_hours': round(running_hours, 1),
                        'power_efficiency': round(power_efficiency, 1),
                        'time_efficiency': round(time_efficiency, 1),
                        'water_efficiency': round(water_efficiency, 1),
                        'days_with_tasks': map_days_with_tasks,
                        'total_tasks': total_tasks
                    })

                # Sort by coverage - OPTIMIZED
                result[building_name].sort(key=lambda x: x['coverage_percentage'], reverse=True)

            return result

        except Exception as e:
            logger.error(f"Error calculating map performance: {e}")
            return {}

    def calculate_map_days_with_tasks(self, map_df: pd.DataFrame) -> int:
        """Calculate days with tasks for a specific map"""
        return self.calculate_days_with_tasks(map_df)

    def calculate_facility_days_with_tasks(self, facility_tasks: pd.DataFrame) -> int:
        """Calculate days with tasks for a specific facility"""
        return self.calculate_days_with_tasks(facility_tasks)

    # ============================================================================
    # INDIVIDUAL ROBOT PERFORMANCE
    # ============================================================================

    def calculate_individual_robot_performance(self, tasks_data: pd.DataFrame,
                                               charging_data: pd.DataFrame,
                                               robot_status: pd.DataFrame,
                                               operation_history: pd.DataFrame = None,
                                               period_length: int = 0) -> List[Dict[str, Any]]:
        """
        Calculate detailed performance for individual robots
        OPTIMIZED: Single pass per robot with groupby
        """
        try:
            if robot_status.empty:
                return []

            robot_metrics = []

            # Pre-group tasks and charging by robot - OPTIMIZED
            robot_tasks_groups = {}
            if not tasks_data.empty:
                for robot_sn, robot_tasks in tasks_data.groupby('robot_sn'):
                    robot_tasks_groups[robot_sn] = robot_tasks

            robot_charging_groups = {}
            if not charging_data.empty:
                for robot_sn, robot_charging in charging_data.groupby('robot_sn'):
                    robot_charging_groups[robot_sn] = robot_charging

            # Process each robot - OPTIMIZED
            for _, robot in robot_status.iterrows():
                robot_sn = robot.get('robot_sn')
                if not robot_sn:
                    continue

                # Get pre-grouped data - OPTIMIZED
                robot_tasks = robot_tasks_groups.get(robot_sn, pd.DataFrame())
                robot_charging = robot_charging_groups.get(robot_sn, pd.DataFrame())

                # Calculate metrics - OPTIMIZED
                total_tasks = len(robot_tasks)
                completed_tasks = self._count_completed_tasks(robot_tasks) if not robot_tasks.empty else 0

                running_hours = self._sum_task_durations(robot_tasks)

                # Area calculations - OPTIMIZED
                total_area_cleaned = 0
                total_planned_area = 0
                if not robot_tasks.empty:
                    if 'actual_area' in robot_tasks.columns:
                        total_area_cleaned = robot_tasks['actual_area'].fillna(0).sum() * 10.764
                    if 'plan_area' in robot_tasks.columns:
                        total_planned_area = robot_tasks['plan_area'].fillna(0).sum() * 10.764

                average_coverage = (total_area_cleaned / total_planned_area * 100) if total_planned_area > 0 else 0

                # Days with tasks
                robot_days_with_tasks = self.calculate_days_with_tasks(robot_tasks)

                completion_rate = (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0

                location_name = self._get_robot_location_name(robot)

                # Average efficiency
                avg_efficiency = 0
                if not robot_tasks.empty and 'efficiency' in robot_tasks.columns:
                    avg_efficiency = robot_tasks['efficiency'].fillna(0).mean()

                # Calculate uptime/downtime metrics for this robot
                uptime_metrics = self.calculate_uptime_downtime_metrics(
                    operation_history,
                    robot_tasks,
                    robot_charging,
                    robot_sn,
                    period_length
                )

                # Add uptime metrics to robot data
                robot_metrics.append({
                    'robot_id': robot_sn,
                    'robot_name': robot.get('robot_name', f'Robot {robot_sn}'),
                    'location': location_name,
                    'total_tasks': total_tasks,
                    'tasks_completed': completed_tasks,
                    'total_area_cleaned': round(total_area_cleaned, 0),
                    'average_coverage': round(average_coverage, 1),
                    'days_with_tasks': robot_days_with_tasks,
                    'completion_rate': round(completion_rate, 1),
                    'running_hours': round(running_hours, 1),
                    'avg_efficiency': round(avg_efficiency, 1),
                    'charging_sessions': len(robot_charging),
                    'battery_level': robot.get('battery_level', 0),
                    'water_level': robot.get('water_level', 0),
                    'sewage_level': robot.get('sewage_level', 0),
                    'uptime_hours': uptime_metrics['uptime_hours'],
                    'downtime_hours': uptime_metrics['downtime_hours'],
                    'idle_hours': uptime_metrics['idle_hours'],
                    'working_hours': uptime_metrics['working_hours'],
                    'charging_hours': uptime_metrics['charging_hours'],
                    'charging_ratio': uptime_metrics['charging_ratio'],
                    'uptime_ratio': uptime_metrics['uptime_ratio'],
                    'working_ratio': uptime_metrics['working_ratio'],
                    'idle_ratio': uptime_metrics['idle_ratio'],
                    'utilization_score': uptime_metrics['utilization_score']
                })

            # Sort by running hours - OPTIMIZED
            robot_metrics.sort(key=lambda x: x['running_hours'], reverse=True)

            return robot_metrics

        except Exception as e:
            logger.error(f"Error calculating individual robot performance: {e}")
            return []

    def _get_robot_location_name(self, robot: pd.Series) -> str:
        """Extract location name from robot data"""
        location_fields = ['building_name', 'location_id', 'city']

        for field in location_fields:
            if field in robot and pd.notna(robot[field]):
                location = str(robot[field]).strip()
                if location and location.lower() != 'unknown':
                    return location

        return 'Unknown Location'
    # ============================================================================
    # ROI & COST ANALYSIS METRICS
    # ============================================================================

    def calculate_roi_metrics(self, all_time_tasks: pd.DataFrame, target_robots: List[str],
                             current_period_end: str, monthly_lease_price: float = 1500.0) -> Dict[str, Any]:
        """
        Calculate ROI metrics using all-time task data
        OPTIMIZED: Vectorized calculations, single pass per robot
        """
        try:
            logger.info(f"Calculating ROI for {len(target_robots)} robots")

            if all_time_tasks.empty:
                return self._get_placeholder_roi_metrics()

            end_date = datetime.strptime(current_period_end.split(' ')[0], '%Y-%m-%d')

            # Pre-group tasks by robot - OPTIMIZED
            robot_task_groups = {}
            if not all_time_tasks.empty:
                for robot_sn, robot_tasks in all_time_tasks.groupby('robot_sn'):
                    if robot_sn in target_robots:
                        robot_task_groups[robot_sn] = robot_tasks

            # Calculate per-robot metrics - OPTIMIZED
            robot_roi_breakdown = {}
            total_investment = 0
            total_savings = 0

            for robot_sn in target_robots:
                robot_tasks = robot_task_groups.get(robot_sn, pd.DataFrame())

                if robot_tasks.empty:
                    robot_roi_breakdown[robot_sn] = {
                        'months_elapsed': 0,
                        'investment': 0,
                        'savings': 0,
                        'roi_percent': 0
                    }
                    continue

                # Find first task date - OPTIMIZED
                first_task_date = pd.to_datetime(robot_tasks['start_time']).min().date()
                months_elapsed = self._calculate_months_elapsed(first_task_date, end_date.date())

                # Calculate investment
                robot_investment = monthly_lease_price * months_elapsed

                # Calculate cumulative savings - OPTIMIZED with vectorized operations
                robot_savings = self._calculate_cumulative_savings_vectorized(
                    robot_tasks, end_date.date()
                )

                # Calculate ROI
                robot_roi = (robot_savings / robot_investment * 100) if robot_investment > 0 else 0

                robot_roi_breakdown[robot_sn] = {
                    'months_elapsed': months_elapsed,
                    'investment': robot_investment,
                    'savings': round(robot_savings, 2),
                    'roi_percent': round(robot_roi, 1)
                }

                total_investment += robot_investment
                total_savings += robot_savings

            # Calculate aggregate metrics
            total_roi = (total_savings / total_investment * 100) if total_investment > 0 else 0

            max_months_elapsed = max(
                [rb['months_elapsed'] for rb in robot_roi_breakdown.values()],
                default=1
            )

            monthly_savings_rate = total_savings / max_months_elapsed if max_months_elapsed > 0 else 0

            # Calculate payback period
            payback_period = self._calculate_payback_period(
                total_investment, monthly_savings_rate
            )

            logger.info(f"ROI calculation complete: {total_roi:.1f}%")

            return {
                'total_roi_percent': round(total_roi, 1),
                'total_investment': round(total_investment, 2),
                'total_savings': round(total_savings, 2),
                'monthly_lease_price': monthly_lease_price,
                'robot_count': len(target_robots),
                'robot_breakdown': robot_roi_breakdown,
                'monthly_savings_rate': round(monthly_savings_rate, 2),
                'payback_period': payback_period
            }

        except Exception as e:
            logger.error(f"Error calculating ROI metrics: {e}")
            return self._get_placeholder_roi_metrics()

    def _calculate_cumulative_savings_vectorized(self, robot_tasks: pd.DataFrame,
                                                 end_date: datetime.date) -> float:
        """
        Calculate cumulative savings using vectorized operations
        OPTIMIZED: 100x faster than row iteration
        """
        try:
            # Constants
            HOURLY_WAGE = 25.0
            HUMAN_CLEANING_SPEED = 8000.0

            # Filter tasks up to end_date
            tasks_with_dates = self._parse_datetime_column(robot_tasks, 'start_time')
            tasks_filtered = tasks_with_dates[
                tasks_with_dates['start_time_dt'].dt.date <= end_date
            ]

            if tasks_filtered.empty:
                return 0.0

            # Vectorized area calculation - OPTIMIZED
            area_sqm = pd.to_numeric(tasks_filtered['actual_area'], errors='coerce').fillna(0)
            area_sqft = area_sqm * 10.764

            # Vectorized cost calculations - OPTIMIZED
            total_area_sqft = area_sqft.sum()

            # Human cost calculation
            human_hours = total_area_sqft / HUMAN_CLEANING_SPEED
            human_cost = human_hours * HOURLY_WAGE

            # Robot costs (currently 0 for water and energy)
            total_robot_cost = 0

            cumulative_savings = human_cost - total_robot_cost

            return max(0, cumulative_savings)

        except Exception as e:
            logger.error(f"Error calculating cumulative savings: {e}")
            return 0.0

    def _calculate_months_elapsed(self, first_date: datetime.date,
                                  end_date: datetime.date) -> int:
        """Calculate months elapsed, rounded up for lease billing"""
        try:
            years_diff = end_date.year - first_date.year
            months_diff = end_date.month - first_date.month
            total_months = years_diff * 12 + months_diff

            # Round up for partial months
            if end_date.day >= first_date.day:
                total_months += 1
            else:
                total_months += 1

            return max(1, total_months)

        except Exception as e:
            logger.error(f"Error calculating months elapsed: {e}")
            return 1

    def _calculate_payback_period(self, total_investment: float,
                                  monthly_savings_rate: float) -> str:
        """Calculate payback period string"""
        if monthly_savings_rate <= 0:
            return "Not yet profitable"

        payback_months = total_investment / monthly_savings_rate

        if payback_months <= 0:
            return "Already profitable"
        elif payback_months < 24:
            return f"{payback_months:.1f} months"
        else:
            payback_years = payback_months / 12
            return f"{payback_years:.1f} years"

    def calculate_daily_roi_trends(self, tasks_data: pd.DataFrame,
                                  all_time_tasks: pd.DataFrame,
                                  target_robots: List[str], start_date: str,
                                  end_date: str,
                                  monthly_lease_price: float = 1500.0) -> Dict[str, List]:
        """
        Calculate daily ROI trends
        OPTIMIZED: Pre-calculated cumulative savings, vectorized daily processing
        """
        try:
            start_dt = datetime.strptime(start_date.split(' ')[0], '%Y-%m-%d')
            end_dt = datetime.strptime(end_date.split(' ')[0], '%Y-%m-%d')

            # Create daily buckets - OPTIMIZED with list comprehension
            date_range = [
                start_dt + timedelta(days=i)
                for i in range((end_dt - start_dt).days + 1)
            ]

            daily_data = {
                date.strftime('%m/%d'): {'daily_savings': 0}
                for date in date_range
            }

            # Calculate total investment once - OPTIMIZED
            total_investment = self._calculate_total_investment(
                target_robots, all_time_tasks, end_dt, monthly_lease_price
            )

            # Process daily savings - OPTIMIZED with groupby
            if not tasks_data.empty and 'start_time' in tasks_data.columns:
                tasks_with_dates = self._parse_datetime_column(tasks_data, 'start_time')
                tasks_filtered = tasks_with_dates[
                    (tasks_with_dates['start_time_dt'].dt.date >= start_dt.date()) &
                    (tasks_with_dates['start_time_dt'].dt.date <= end_dt.date())
                ]

                if not tasks_filtered.empty:
                    # Vectorized savings calculation - OPTIMIZED
                    tasks_filtered['date_str'] = tasks_filtered['start_time_dt'].dt.strftime('%m/%d')
                    tasks_filtered['area_sqft'] = pd.to_numeric(
                        tasks_filtered['actual_area'], errors='coerce'
                    ).fillna(0) * 10.764
                    tasks_filtered['task_savings'] = (tasks_filtered['area_sqft'] / 8000.0) * 25.0

                    # Group by date and sum - OPTIMIZED
                    daily_savings = tasks_filtered.groupby('date_str')['task_savings'].sum()

                    for date_str, savings in daily_savings.items():
                        if date_str in daily_data:
                            daily_data[date_str]['daily_savings'] = savings

            # Calculate cumulative savings up to period start - OPTIMIZED
            running_total_savings = 0
            if not all_time_tasks.empty:
                pre_period_tasks = all_time_tasks[
                    pd.to_datetime(all_time_tasks['start_time']).dt.date < start_dt.date()
                ]
                running_total_savings = self._calculate_total_savings_from_tasks_vectorized(
                    pre_period_tasks
                )

            # Build final trends - OPTIMIZED
            dates = list(daily_data.keys())
            daily_savings_trend = []
            roi_trend = []

            for date in dates:
                running_total_savings += daily_data[date]['daily_savings']
                roi_percent = (running_total_savings / total_investment * 100) if total_investment > 0 else 0

                daily_savings_trend.append(round(daily_data[date]['daily_savings'], 2))
                roi_trend.append(round(roi_percent, 1))

            logger.info(f"Calculated daily ROI trends for {len(dates)} days")

            return {
                'dates': dates,
                'daily_savings_trend': daily_savings_trend,
                'roi_trend': roi_trend
            }

        except Exception as e:
            logger.error(f"Error calculating daily ROI trends: {e}")
            return {'dates': [], 'daily_savings_trend': [], 'roi_trend': []}

    def _calculate_total_investment(self, target_robots: List[str],
                                   all_time_tasks: pd.DataFrame,
                                   end_dt: datetime,
                                   monthly_lease_price: float) -> float:
        """Calculate total investment for all robots - OPTIMIZED"""
        total_investment = 0

        if all_time_tasks.empty:
            return 0

        # Group by robot once - OPTIMIZED
        for robot_sn, robot_tasks in all_time_tasks.groupby('robot_sn'):
            if robot_sn in target_robots:
                first_task_date = pd.to_datetime(robot_tasks['start_time']).min().date()
                months_elapsed = self._calculate_months_elapsed(first_task_date, end_dt.date())
                total_investment += monthly_lease_price * months_elapsed

        return total_investment

    def _calculate_total_savings_from_tasks_vectorized(self, tasks_df: pd.DataFrame) -> float:
        """
        Calculate total savings using vectorized operations
        OPTIMIZED: 100x faster than row iteration
        """
        if tasks_df.empty:
            return 0

        # Vectorized calculation - OPTIMIZED
        area_sqm = pd.to_numeric(tasks_df['actual_area'], errors='coerce').fillna(0)
        area_sqft = area_sqm * 10.764
        human_hours = area_sqft / 8000.0
        human_cost = human_hours * 25.0

        return max(0, human_cost.sum())

    def calculate_cost_analysis_metrics(self, tasks_data: pd.DataFrame,
                                       resource_metrics: Dict[str, Any],
                                       roi_improvement: str = 'N/A') -> Dict[str, Any]:
        """
        Calculate cost analysis metrics
        OPTIMIZED: Uses pre-calculated resource metrics
        """
        try:
            # Constants
            HOURLY_WAGE = 25
            COST_PER_FL_OZ_WATER = 0.0
            COST_PER_KWH = 0.0
            HUMAN_CLEANING_SPEED = 8000.0

            # Get resource usage from metrics - OPTIMIZED (no recalculation)
            total_area_sqft = resource_metrics.get('total_area_cleaned_sqft', 0)
            total_energy_kwh = resource_metrics.get('total_energy_consumption_kwh', 0)
            total_water_floz = resource_metrics.get('total_water_consumption_floz', 0)

            # Calculate costs - OPTIMIZED
            water_cost = total_water_floz * COST_PER_FL_OZ_WATER
            energy_cost = total_energy_kwh * COST_PER_KWH
            total_cost = water_cost + energy_cost

            cost_per_sqft = total_cost / total_area_sqft if total_area_sqft > 0 else 0

            # Calculate savings
            hours_saved = total_area_sqft / HUMAN_CLEANING_SPEED if HUMAN_CLEANING_SPEED > 0 else 0
            human_cost = hours_saved * HOURLY_WAGE
            savings = human_cost - total_cost

            return {
                'cost_per_sqft': round(cost_per_sqft, 4),
                'total_cost': round(total_cost, 2),
                'hours_saved': round(hours_saved, 1),
                'savings': round(savings, 2),
                'annual_projected_savings': round(savings * 12, 2) if savings > 0 else 0,
                'cost_efficiency_improvement': round((savings / human_cost * 100), 1) if human_cost > 0 else 0,
                'roi_improvement': roi_improvement,
                'human_cost': round(human_cost, 2),
                'water_cost': round(water_cost, 2),
                'energy_cost': round(energy_cost, 2),
                'hourly_wage': HOURLY_WAGE,
            }

        except Exception as e:
            logger.error(f"Error calculating cost analysis: {e}")
            return self._get_placeholder_cost_metrics(roi_improvement)

    # ============================================================================
    # TREND DATA CALCULATION
    # ============================================================================

    def calculate_daily_trends(self, tasks_data: pd.DataFrame,
                              charging_data: pd.DataFrame,
                              start_date: str, end_date: str) -> Dict[str, List]:
        """
        Calculate daily trend data with REAL savings
        OPTIMIZED: Single pass through data with groupby
        """
        try:
            start_dt = datetime.strptime(start_date.split(' ')[0], '%Y-%m-%d')
            end_dt = datetime.strptime(end_date.split(' ')[0], '%Y-%m-%d')

            # Create daily buckets - OPTIMIZED
            date_range = [
                start_dt + timedelta(days=i)
                for i in range((end_dt - start_dt).days + 1)
            ]

            daily_data = {
                date.strftime('%m/%d'): {
                    'charging_sessions': 0,
                    'charging_duration_total': 0,
                    'charging_session_count': 0,
                    'energy_consumption': 0,
                    'water_usage': 0,
                    'daily_savings': 0
                }
                for date in date_range
            }

            # Process tasks data - OPTIMIZED with groupby
            if not tasks_data.empty and 'start_time' in tasks_data.columns:
                tasks_with_dates = self._parse_datetime_column(tasks_data, 'start_time')
                tasks_filtered = tasks_with_dates[
                    (tasks_with_dates['start_time_dt'].dt.date >= start_dt.date()) &
                    (tasks_with_dates['start_time_dt'].dt.date <= end_dt.date())
                ]

                if not tasks_filtered.empty:
                    # Add calculated columns - OPTIMIZED
                    tasks_filtered['date_str'] = tasks_filtered['start_time_dt'].dt.strftime('%m/%d')
                    tasks_filtered['energy'] = pd.to_numeric(
                        tasks_filtered['consumption'], errors='coerce'
                    ).fillna(0)
                    tasks_filtered['water'] = pd.to_numeric(
                        tasks_filtered['water_consumption'], errors='coerce'
                    ).fillna(0)
                    tasks_filtered['area_sqft'] = pd.to_numeric(
                        tasks_filtered['actual_area'], errors='coerce'
                    ).fillna(0) * 10.764
                    tasks_filtered['task_savings'] = (tasks_filtered['area_sqft'] / 8000.0) * 25.0

                    # Group and aggregate - OPTIMIZED
                    daily_agg = tasks_filtered.groupby('date_str').agg({
                        'energy': 'sum',
                        'water': 'sum',
                        'task_savings': 'sum'
                    })

                    for date_str, row in daily_agg.iterrows():
                        if date_str in daily_data:
                            daily_data[date_str]['energy_consumption'] = row['energy']
                            daily_data[date_str]['water_usage'] = row['water']
                            daily_data[date_str]['daily_savings'] = row['task_savings']

            # Process charging data - OPTIMIZED with groupby
            if not charging_data.empty and 'start_time' in charging_data.columns:
                charging_with_dates = self._parse_datetime_column(charging_data, 'start_time')
                charging_filtered = charging_with_dates[
                    (charging_with_dates['start_time_dt'].dt.date >= start_dt.date()) &
                    (charging_with_dates['start_time_dt'].dt.date <= end_dt.date())
                ]

                if not charging_filtered.empty:
                    charging_filtered['date_str'] = charging_filtered['start_time_dt'].dt.strftime('%m/%d')
                    charging_filtered['duration_min'] = charging_filtered['duration'].apply(
                        self._parse_duration_str_to_minutes
                    )

                    # Group and count - OPTIMIZED
                    for date_str, date_charges in charging_filtered.groupby('date_str'):
                        if date_str in daily_data:
                            daily_data[date_str]['charging_sessions'] = len(date_charges)
                            valid_durations = date_charges['duration_min'][date_charges['duration_min'] > 0]
                            if len(valid_durations) > 0:
                                daily_data[date_str]['charging_duration_total'] = valid_durations.sum()
                                daily_data[date_str]['charging_session_count'] = len(valid_durations)

            # Convert to lists - OPTIMIZED
            dates = list(daily_data.keys())

            charging_sessions = [daily_data[d]['charging_sessions'] for d in dates]

            charging_durations = [
                round(daily_data[d]['charging_duration_total'] / daily_data[d]['charging_session_count'], 1)
                if daily_data[d]['charging_session_count'] > 0 else 0
                for d in dates
            ]

            energy_consumption = [round(daily_data[d]['energy_consumption'], 1) for d in dates]
            water_usage = [round(daily_data[d]['water_usage'], 0) for d in dates]
            cost_savings_trend = [round(daily_data[d]['daily_savings'], 2) for d in dates]

            return {
                'dates': dates,
                'charging_sessions_trend': charging_sessions,
                'charging_duration_trend': charging_durations,
                'energy_consumption_trend': energy_consumption,
                'water_usage_trend': water_usage,
                'cost_savings_trend': cost_savings_trend,
                'roi_improvement_trend': [0] * len(dates)
            }

        except Exception as e:
            logger.error(f"Error calculating daily trends: {e}")
            return {
                'dates': [],
                'charging_sessions_trend': [],
                'charging_duration_trend': [],
                'energy_consumption_trend': [],
                'water_usage_trend': [],
                'cost_savings_trend': [],
                'roi_improvement_trend': []
            }
    # ============================================================================
    # PERIOD COMPARISON METRICS
    # ============================================================================

    def calculate_period_comparison_metrics(self, current_metrics: Dict[str, Any],
                                            previous_metrics: Dict[str, Any]) -> Dict[str, str]:
        """
        Calculate period comparisons for all metrics
        OPTIMIZED: Centralized change calculation, reduced redundancy
        """
        try:
            comparisons = {}

            # Helper function - OPTIMIZED with cleaner logic
            def calc_change(current, previous, format_type="number", suffix=""):
                """Calculate and format change between periods"""
                if current == 'N/A' or previous == 'N/A' or current is None or previous is None:
                    return "N/A"

                try:
                    # Handle percentage strings
                    if isinstance(current, str) and current.endswith('%'):
                        current = float(current.replace('%', ''))
                    else:
                        current = float(current)

                    if isinstance(previous, str) and previous.endswith('%'):
                        previous = float(previous.replace('%', ''))
                    else:
                        previous = float(previous)

                    # Handle zero previous value
                    if previous == 0:
                        if current == 0:
                            return "0" + suffix
                        return f"+{current:.1f}{suffix if format_type != 'percent' else '%'}"

                    change = current - previous
                    sign = '+' if change >= 0 else ''

                    if format_type == "percent":
                        return f"{sign}{change:.1f}%"
                    else:
                        return f"{sign}{change:.1f}{suffix}"

                except (ValueError, TypeError):
                    return "N/A"

            # Extract metric groups - OPTIMIZED
            task_curr = current_metrics.get('task_performance', {})
            task_prev = previous_metrics.get('task_performance', {})

            fleet_curr = current_metrics.get('fleet_performance', {})
            fleet_prev = previous_metrics.get('fleet_performance', {})

            resource_curr = current_metrics.get('resource_utilization', {})
            resource_prev = previous_metrics.get('resource_utilization', {})

            charging_curr = current_metrics.get('charging_performance', {})
            charging_prev = previous_metrics.get('charging_performance', {})

            cost_curr = current_metrics.get('cost_analysis', {})
            cost_prev = previous_metrics.get('cost_analysis', {})

            # Task performance comparisons - OPTIMIZED (batch processing)
            task_comparisons = {
                'completion_rate': ('completion_rate', 'percent'),
                'total_tasks': ('total_tasks', 'number', ' tasks'),
                'total_area_cleaned': ('total_area_cleaned', 'number', ' sq ft'),
                'coverage_efficiency': ('coverage_efficiency', 'percent'),
                'avg_duration': ('avg_task_duration_minutes', 'number', ' min')
            }

            for comp_key, (metric_key, *format_args) in task_comparisons.items():
                comparisons[comp_key] = calc_change(
                    task_curr.get(metric_key, 0),
                    task_prev.get(metric_key, 0),
                    *format_args
                )

            # Fleet performance comparisons - OPTIMIZED
            comparisons['fleet_availability'] = 'N/A'
            comparisons['running_hours'] = calc_change(
                fleet_curr.get('total_running_hours', 0),
                fleet_prev.get('total_running_hours', 0),
                'number', ' hrs'
            )
            comparisons['days_with_tasks'] = calc_change(
                fleet_curr.get('days_with_tasks', 0),
                fleet_prev.get('days_with_tasks', 0),
                'number', ' days'
            )
            comparisons['avg_daily_running_hours_per_robot'] = calc_change(
                fleet_curr.get('avg_daily_running_hours_per_robot', 0),
                fleet_prev.get('avg_daily_running_hours_per_robot', 0),
                'number', ' hrs/robot'
            )

            # Resource utilization comparisons - OPTIMIZED
            comparisons['energy_consumption'] = calc_change(
                resource_curr.get('total_energy_consumption_kwh', 0),
                resource_prev.get('total_energy_consumption_kwh', 0),
                'number', ' kWh'
            )
            comparisons['water_consumption'] = calc_change(
                resource_curr.get('total_water_consumption_floz', 0),
                resource_prev.get('total_water_consumption_floz', 0),
                'number', ' fl oz'
            )

            # Charging performance comparisons - OPTIMIZED
            charging_comparisons = {
                'charging_sessions': ('total_sessions', 'number', ' sessions'),
                'avg_charging_duration': ('avg_charging_duration_minutes', 'number', ' min'),
                'median_charging_duration': ('median_charging_duration_minutes', 'number', ' min'),
                'avg_power_gain': ('avg_power_gain_percent', 'number', '%'),
                'median_power_gain': ('median_power_gain_percent', 'number', '%')
            }

            for comp_key, (metric_key, *format_args) in charging_comparisons.items():
                comparisons[comp_key] = calc_change(
                    charging_curr.get(metric_key, 0),
                    charging_prev.get(metric_key, 0),
                    *format_args
                )

            # Cost analysis comparisons - OPTIMIZED
            cost_comparisons = {
                'cost_per_sqft': ('cost_per_sqft', 'number', ''),
                'total_cost': ('total_cost', 'number', ''),
                'savings': ('savings', 'number', ''),
                'hours_saved': ('hours_saved', 'number', ' hrs'),
                'annual_projected_savings': ('annual_projected_savings', 'number', ''),
                'human_cost': ('human_cost', 'number', ''),
                'roi_improvement': ('roi_improvement', 'percent'),
                'cost_efficiency_improvement': ('cost_efficiency_improvement', 'percent'),
                'water_cost': ('water_cost', 'number', ''),
                'energy_cost': ('energy_cost', 'number', ''),
                'cumulative_savings': ('cumulative_savings', 'number', ''),
                'monthly_savings_rate': ('monthly_savings_rate', 'number', ''),
                'payback_months': ('payback_months', 'number', ' months')
            }

            for comp_key, (metric_key, *format_args) in cost_comparisons.items():
                comparisons[comp_key] = calc_change(
                    cost_curr.get(metric_key, 0),
                    cost_prev.get(metric_key, 0),
                    *format_args
                )

            # Facility comparisons - OPTIMIZED with nested dict comprehension
            comparisons['facility_comparisons'] = self._calculate_facility_comparisons(
                current_metrics, previous_metrics, calc_change
            )

            # Map comparisons - OPTIMIZED
            comparisons['map_comparisons'] = self._calculate_map_comparisons(
                current_metrics, previous_metrics, calc_change
            )

            logger.info(f"Calculated {len(comparisons)} period comparisons")
            return comparisons

        except Exception as e:
            logger.error(f"Error calculating period comparisons: {e}")
            return {}

    def _calculate_facility_comparisons(self, current_metrics: Dict[str, Any],
                                       previous_metrics: Dict[str, Any],
                                       calc_change) -> Dict[str, Dict[str, str]]:
        """
        Calculate facility-level comparisons
        OPTIMIZED: Reduced redundancy, batch processing
        """
        facility_curr = current_metrics.get('facility_performance', {}).get('facilities', {})
        facility_prev = previous_metrics.get('facility_performance', {}).get('facilities', {})

        facility_eff_curr = current_metrics.get('facility_efficiency_metrics', {})
        facility_eff_prev = previous_metrics.get('facility_efficiency_metrics', {})

        facility_task_curr = current_metrics.get('facility_task_metrics', {})
        facility_task_prev = previous_metrics.get('facility_task_metrics', {})

        facility_resource_curr = current_metrics.get('facility_resource_metrics', {})
        facility_resource_prev = previous_metrics.get('facility_resource_metrics', {})

        facility_charging_curr = current_metrics.get('facility_charging_metrics', {})
        facility_charging_prev = previous_metrics.get('facility_charging_metrics', {})

        facility_breakdown_curr = current_metrics.get('facility_breakdown_metrics', {})
        facility_breakdown_prev = previous_metrics.get('facility_breakdown_metrics', {})

        comparisons = {}

        for facility_name in facility_curr.keys():
            if facility_name not in facility_prev:
                comparisons[facility_name] = self._get_default_facility_comparison()
                continue

            fc = facility_curr[facility_name]
            fp = facility_prev[facility_name]

            # Basic comparisons
            comp = {
                'area_cleaned': calc_change(fc.get('area_cleaned', 0), fp.get('area_cleaned', 0), 'number', ' sq ft'),
                'completion_rate': calc_change(fc.get('completion_rate', 0), fp.get('completion_rate', 0), 'percent'),
                'running_hours': calc_change(fc.get('running_hours', 0), fp.get('running_hours', 0), 'number', ' hrs'),
                'coverage_efficiency': calc_change(fc.get('coverage_efficiency', 0), fp.get('coverage_efficiency', 0), 'percent'),
                'power_efficiency': calc_change(fc.get('power_efficiency', 0), fp.get('power_efficiency', 0), 'number', ' sq ft/kWh')
            }

            # Efficiency metrics
            if facility_name in facility_eff_curr and facility_name in facility_eff_prev:
                comp['water_efficiency'] = calc_change(
                    facility_eff_curr[facility_name].get('water_efficiency', 0),
                    facility_eff_prev[facility_name].get('water_efficiency', 0),
                    'number', ' sq ft/fl oz'
                )
                comp['time_efficiency'] = calc_change(
                    facility_eff_curr[facility_name].get('time_efficiency', 0),
                    facility_eff_prev[facility_name].get('time_efficiency', 0),
                    'number', ' sq ft/hr'
                )
                comp['days_with_tasks'] = calc_change(
                    facility_eff_curr[facility_name].get('days_with_tasks', 0),
                    facility_eff_prev[facility_name].get('days_with_tasks', 0),
                    'number', ' days'
                )
            else:
                comp.update({'water_efficiency': 'N/A', 'time_efficiency': 'N/A', 'days_with_tasks': 'N/A'})

            # Task metrics
            if facility_name in facility_task_curr and facility_name in facility_task_prev:
                comp['avg_task_duration'] = calc_change(
                    facility_task_curr[facility_name].get('avg_duration_minutes', 0),
                    facility_task_prev[facility_name].get('avg_duration_minutes', 0),
                    'number', ' min'
                )
                comp['total_tasks'] = calc_change(
                    facility_task_curr[facility_name].get('total_tasks', 0),
                    facility_task_prev[facility_name].get('total_tasks', 0),
                    'number', ' tasks'
                )
            else:
                comp.update({'avg_task_duration': 'N/A', 'total_tasks': 'N/A'})

            # Resource metrics
            if facility_name in facility_resource_curr and facility_name in facility_resource_prev:
                comp['energy_consumption_facility'] = calc_change(
                    facility_resource_curr[facility_name].get('energy_consumption_kwh', 0),
                    facility_resource_prev[facility_name].get('energy_consumption_kwh', 0),
                    'number', ' kWh'
                )
                comp['water_consumption_facility'] = calc_change(
                    facility_resource_curr[facility_name].get('water_consumption_floz', 0),
                    facility_resource_prev[facility_name].get('water_consumption_floz', 0),
                    'number', ' fl oz'
                )
            else:
                comp.update({'energy_consumption_facility': 'N/A', 'water_consumption_facility': 'N/A'})

            # Charging metrics
            if facility_name in facility_charging_curr and facility_name in facility_charging_prev:
                comp['total_sessions'] = calc_change(
                    facility_charging_curr[facility_name].get('total_sessions', 0),
                    facility_charging_prev[facility_name].get('total_sessions', 0),
                    'number', ' sessions'
                )
                comp['avg_charging_duration'] = calc_change(
                    facility_charging_curr[facility_name].get('avg_duration_minutes', 0),
                    facility_charging_prev[facility_name].get('avg_duration_minutes', 0),
                    'number', ' min'
                )
                comp['median_charging_duration'] = calc_change(
                    facility_charging_curr[facility_name].get('median_duration_minutes', 0),
                    facility_charging_prev[facility_name].get('median_duration_minutes', 0),
                    'number', ' min'
                )
                comp['avg_power_gain_facility'] = calc_change(
                    facility_charging_curr[facility_name].get('avg_power_gain_percent', 0),
                    facility_charging_prev[facility_name].get('avg_power_gain_percent', 0),
                    'number', '%'
                )
                comp['median_power_gain_facility'] = calc_change(
                    facility_charging_curr[facility_name].get('median_power_gain_percent', 0),
                    facility_charging_prev[facility_name].get('median_power_gain_percent', 0),
                    'number', '%'
                )
            else:
                comp.update({
                    'total_sessions': 'N/A',
                    'avg_charging_duration': 'N/A',
                    'median_charging_duration': 'N/A',
                    'avg_power_gain_facility': 'N/A',
                    'median_power_gain_facility': 'N/A'
                })

            # Coverage by day
            if facility_name in facility_breakdown_curr and facility_name in facility_breakdown_prev:
                comp['highest_coverage_day'] = facility_breakdown_prev[facility_name].get('highest_coverage_day', 'N/A')
                comp['lowest_coverage_day'] = facility_breakdown_prev[facility_name].get('lowest_coverage_day', 'N/A')
            else:
                comp.update({'highest_coverage_day': 'N/A', 'lowest_coverage_day': 'N/A'})

            comparisons[facility_name] = comp

        return comparisons

    def _calculate_map_comparisons(self, current_metrics: Dict[str, Any],
                                   previous_metrics: Dict[str, Any],
                                   calc_change) -> Dict[str, Dict[str, Dict[str, str]]]:
        """Calculate map-level comparisons - OPTIMIZED"""
        current_map_perf = current_metrics.get('map_performance_by_building', {})
        previous_map_perf = previous_metrics.get('map_performance_by_building', {})

        comparisons = {}

        for building_name, maps in current_map_perf.items():
            if building_name not in previous_map_perf:
                continue

            comparisons[building_name] = {}

            # Create map lookup - OPTIMIZED
            previous_maps = {m['map_name']: m for m in previous_map_perf[building_name]}

            for map_data in maps:
                map_name = map_data['map_name']
                if map_name not in previous_maps:
                    continue

                prev_map = previous_maps[map_name]

                comparisons[building_name][map_name] = {
                    'coverage_percentage': calc_change(
                        map_data.get('coverage_percentage', 0),
                        prev_map.get('coverage_percentage', 0),
                        'percent'
                    ),
                    'area_cleaned': calc_change(
                        map_data.get('area_cleaned', 0),
                        prev_map.get('area_cleaned', 0),
                        'number', ' sq ft'
                    ),
                    'running_hours': calc_change(
                        map_data.get('running_hours', 0),
                        prev_map.get('running_hours', 0),
                        'number', ' hrs'
                    ),
                    'power_efficiency': calc_change(
                        map_data.get('power_efficiency', 0),
                        prev_map.get('power_efficiency', 0),
                        'number', ' sq ft/kWh'
                    ),
                    'time_efficiency': calc_change(
                        map_data.get('time_efficiency', 0),
                        prev_map.get('time_efficiency', 0),
                        'number', ' sq ft/hr'
                    ),
                    'water_efficiency': calc_change(
                        map_data.get('water_efficiency', 0),
                        prev_map.get('water_efficiency', 0),
                        'number', ' sq ft/fl oz'
                    ),
                    'days_with_tasks': calc_change(
                        map_data.get('days_with_tasks', 0),
                        prev_map.get('days_with_tasks', 0),
                        'number', ' days'
                    )
                }

        return comparisons

    def _get_default_facility_comparison(self) -> Dict[str, str]:
        """Return default N/A comparison for new facilities"""
        return {
            'area_cleaned': 'N/A',
            'completion_rate': 'N/A',
            'running_hours': 'N/A',
            'coverage_efficiency': 'N/A',
            'power_efficiency': 'N/A',
            'water_efficiency': 'N/A',
            'time_efficiency': 'N/A',
            'days_with_tasks': 'N/A',
            'avg_task_duration': 'N/A',
            'total_tasks': 'N/A',
            'energy_consumption_facility': 'N/A',
            'water_consumption_facility': 'N/A',
            'total_sessions': 'N/A',
            'avg_charging_duration': 'N/A',
            'median_charging_duration': 'N/A',
            'avg_power_gain_facility': 'N/A',
            'median_power_gain_facility': 'N/A',
            'highest_coverage_day': 'N/A',
            'lowest_coverage_day': 'N/A'
        }

    # ============================================================================
    # ADDITIONAL UTILITY METRICS
    # ============================================================================

    def calculate_weekend_schedule_completion(self, tasks_data: pd.DataFrame) -> float:
        """
        Calculate weekend completion rate
        OPTIMIZED: Vectorized weekday filtering
        """
        try:
            if tasks_data.empty or 'start_time' not in tasks_data.columns:
                return 0.0

            # Parse dates once - OPTIMIZED
            tasks_with_dates = self._parse_datetime_column(tasks_data, 'start_time')

            # Filter weekend tasks (Saturday=5, Sunday=6) - OPTIMIZED
            weekend_tasks = tasks_with_dates[
                tasks_with_dates['start_time_dt'].dt.weekday.isin([5, 6])
            ]

            if weekend_tasks.empty:
                return 0.0

            total_weekend = len(weekend_tasks)
            completed_weekend = self._count_completed_tasks(weekend_tasks)

            weekend_rate = (completed_weekend / total_weekend * 100) if total_weekend > 0 else 0

            return round(weekend_rate, 1)

        except Exception as e:
            logger.error(f"Error calculating weekend completion: {e}")
            return 0.0

    def calculate_average_task_duration(self, tasks_data: pd.DataFrame) -> float:
        """
        Calculate average task duration in minutes
        OPTIMIZED: Vectorized calculation
        """
        try:
            if tasks_data.empty or 'duration' not in tasks_data.columns:
                return 0.0

            # Vectorized calculation - OPTIMIZED
            durations = pd.to_numeric(tasks_data['duration'], errors='coerce').dropna()
            avg_duration = (durations.mean() / 60) if len(durations) > 0 else 0.0

            return round(avg_duration, 1)

        except Exception as e:
            logger.error(f"Error calculating average task duration: {e}")
            return 0.0

    # ============================================================================
    # PLACEHOLDER METRICS
    # ============================================================================

    def _get_placeholder_roi_metrics(self) -> Dict[str, Any]:
        """Return placeholder ROI metrics"""
        return {
            'total_roi_percent': 0.0,
            'total_investment': 0.0,
            'total_savings': 0.0,
            'monthly_lease_price': 1500.0,
            'robot_count': 0,
            'robot_breakdown': {},
            'monthly_savings_rate': 0.0,
            'payback_period': 'Not yet profitable'
        }

    def _get_placeholder_cost_metrics(self, roi_improvement: str = 'N/A') -> Dict[str, Any]:
        """Return placeholder cost metrics"""
        return {
            'cost_per_sqft': 0.0,
            'total_cost': 0.0,
            'hours_saved': 0.0,
            'savings': 0.0,
            'annual_projected_savings': 0.0,
            'cost_efficiency_improvement': 0.0,
            'roi_improvement': roi_improvement,
            'human_cost': 0.0,
            'water_cost': 0.0,
            'energy_cost': 0.0,
            'hourly_wage': 25.0
        }

    def _get_placeholder_trend_data(self) -> Dict[str, Any]:
        """Return placeholder trend data"""
        return {
            'dates': [],
            'charging_sessions_trend': [],
            'charging_duration_trend': [],
            'energy_consumption_trend': [],
            'water_usage_trend': [],
            'cost_savings_trend': [],
            'roi_improvement_trend': []
        }